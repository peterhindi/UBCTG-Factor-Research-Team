{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f623ff5c-f8e1-4442-b4e8-18f2037b10de",
   "metadata": {},
   "source": [
    "<Header> This is is where we develop a baseline factor model that allows us to take certain factors and use them in multi-OLS regression to predict our excess return signals on a security level. These signals are absolute. </Header>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4a69f3-3cbf-4611-bcb6-873c4e4020b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, import our packages for the database connection and dataframe access\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d17be18-1e1f-4c33-867e-3bb0270b3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore warnings and set max row display option\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47003839-a5a3-44f2-96f8-71283b57aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"ubctg.con7266gcvin.us-east-2.rds.amazonaws.com\",\n",
    "    user=\"admin\",\n",
    "    password=\"ubctgquant\",\n",
    "    database=\"ubctg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5810ea6d-5c42-4cc7-a604-c39ef9ca7b4a",
   "metadata": {},
   "source": [
    "Here, we pull monthly returns across the stock universe over 10 years from 2011 to 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79941fa5-f63f-413b-bf06-487a9c135368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a cursor object to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2020-06-01'\n",
    "end_date = '2021-01-31'\n",
    "\n",
    "# SQL query to retrieve data from the \"Volatility\" table between two dates\n",
    "sql_query = f\"SELECT * FROM `Monthly Returns` mr WHERE Date BETWEEN '{start_date}' AND '{end_date}'\"\n",
    "\n",
    "# Execute the SQL query\n",
    "cursor.execute(sql_query)\n",
    "\n",
    "# Fetch all rows from the result set\n",
    "universe_data = cursor.fetchall()\n",
    "\n",
    "# Convert fetched data into a pandas DataFrame\n",
    "columns = [i[0] for i in cursor.description]  # Extract column names from cursor description\n",
    "\n",
    "#create new df\n",
    "universe_df = pd.DataFrame(universe_data, columns=columns)\n",
    "\n",
    "#close cursor and db connection\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f68ab0-defa-4fa5-9b1b-047f9b024028",
   "metadata": {},
   "source": [
    "Generate the number of observations per security in our table. This way we can remove those that do not have a full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c2e210-9703-44cb-8f27-981f24f2ce4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a cursor object to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2020-06-01'\n",
    "end_date = '2021-01-31'\n",
    "\n",
    "# SQL query to retrieve data from the \"Volatility\" table between two dates\n",
    "sql_query = f\"SELECT COUNT(PERMNO), PERMNO FROM `Monthly Returns` mr WHERE Date BETWEEN '{start_date}' AND '{end_date}' GROUP BY PERMNO\"\n",
    "\n",
    "# Execute the SQL query\n",
    "cursor.execute(sql_query)\n",
    "\n",
    "# Fetch all rows from the result set\n",
    "observationTable_data = cursor.fetchall()\n",
    "\n",
    "# Convert fetched data into a pandas DataFrame\n",
    "columns = [i[0] for i in cursor.description]  # Extract column names from cursor description\n",
    "\n",
    "#create new df\n",
    "observation_df = pd.DataFrame(observationTable_data, columns=columns)\n",
    "\n",
    "#close cursor and db connection\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25953b38-02ce-49d4-b7d8-2761f2bf8abf",
   "metadata": {},
   "source": [
    "Here, we remove securities that do not have enough observations (in our case, we look for at least 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b89c583-b56a-4f9a-995c-90f4f2183df0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Filter securities with at least 120 observations in the period\n",
    "observation_df_filtered = observation_df[pd.to_numeric(observation_df['COUNT(PERMNO)'])>=8]\n",
    "\n",
    "#Inner join our dataframes to only keep the securities we have data on\n",
    "universe_df_filtered = pd.merge(universe_df, observation_df_filtered, on='PERMNO', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bc8333-c612-4af9-a405-298e3772612d",
   "metadata": {},
   "source": [
    "We can now add a few factors to our model, in this case we will use GDP, CPI (inflation data), and the unemployment rate in each month. We then add it to our monthly returns dataframe for our OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a69fd4-a887-4229-9f71-72b85399c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduce our factor data below as a CSV (pandas datareader not currently working for FRED api)\n",
    "macro_factors = pd.read_csv(\"UBCTG Factor Model Example - Macro FRED Data.csv\")\n",
    "\n",
    "#These dates are at the beginning of month, so we will operate on our monthly return dataframe to convert our dates to the beginning of the month so that we can append on index\n",
    "universe_df_filtered[\"date\"] = pd.to_datetime(universe_df_filtered[\"date\"]).dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "#Convert macro factors date column to type datetime64 and drop the non-datetime64 column\n",
    "macro_factors[\"date\"] = pd.to_datetime(macro_factors[\"DATE\"])\n",
    "macro_factors = macro_factors.drop('DATE', axis=1)\n",
    "\n",
    "#Inner-join macro factors dataframe with universe dataframe, using 'date' column as index\n",
    "universe_df_with_external_factors = pd.merge(universe_df_filtered, macro_factors, on= 'date', how='inner')\n",
    "\n",
    "#Ensure no errors in the returns column (there have been some instances where returns have taken on non-numeric values)\n",
    "universe_df_with_external_factors[\"RET\"] = pd.to_numeric(universe_df_with_external_factors[\"RET\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "067395fe-9ae7-464d-b2c5-f3a9dacbc2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>Annualized Percent Change of GDP from Preceding Period, Seasonally Adjusted</th>\n",
       "      <th>CPI (USACPALTT01CTGYM)</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026.0</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>0.104118</td>\n",
       "      <td>45.954756</td>\n",
       "      <td>0.933336</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10026.0</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>-0.036668</td>\n",
       "      <td>32.804157</td>\n",
       "      <td>1.264507</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026.0</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>0.039727</td>\n",
       "      <td>10.259221</td>\n",
       "      <td>1.332004</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026.0</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>-3.677010</td>\n",
       "      <td>1.130982</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10026.0</td>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>0.072598</td>\n",
       "      <td>-4.401027</td>\n",
       "      <td>1.122155</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60419</th>\n",
       "      <td>93436.0</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>-0.095499</td>\n",
       "      <td>10.259221</td>\n",
       "      <td>1.332004</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60420</th>\n",
       "      <td>93436.0</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0.462736</td>\n",
       "      <td>-3.677010</td>\n",
       "      <td>1.130982</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60421</th>\n",
       "      <td>93436.0</td>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>-4.401027</td>\n",
       "      <td>1.122155</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60422</th>\n",
       "      <td>93436.0</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>0.124506</td>\n",
       "      <td>3.579485</td>\n",
       "      <td>1.323012</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60423</th>\n",
       "      <td>93436.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.270387</td>\n",
       "      <td>1.365916</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52922 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PERMNO       date       RET  \\\n",
       "1      10026.0 2020-07-01  0.104118   \n",
       "2      10026.0 2020-08-01 -0.036668   \n",
       "3      10026.0 2020-09-01  0.039727   \n",
       "4      10026.0 2020-10-01  0.072435   \n",
       "5      10026.0 2020-11-01  0.072598   \n",
       "...        ...        ...       ...   \n",
       "60419  93436.0 2020-09-01 -0.095499   \n",
       "60420  93436.0 2020-10-01  0.462736   \n",
       "60421  93436.0 2020-11-01  0.243252   \n",
       "60422  93436.0 2020-12-01  0.124506   \n",
       "60423  93436.0 2021-01-01       NaN   \n",
       "\n",
       "       Annualized Percent Change of GDP from Preceding Period, Seasonally Adjusted  \\\n",
       "1                                              45.954756                             \n",
       "2                                              32.804157                             \n",
       "3                                              10.259221                             \n",
       "4                                              -3.677010                             \n",
       "5                                              -4.401027                             \n",
       "...                                                  ...                             \n",
       "60419                                          10.259221                             \n",
       "60420                                          -3.677010                             \n",
       "60421                                          -4.401027                             \n",
       "60422                                           3.579485                             \n",
       "60423                                           8.270387                             \n",
       "\n",
       "       CPI (USACPALTT01CTGYM)  UNRATE  \n",
       "1                    0.933336    10.2  \n",
       "2                    1.264507     8.4  \n",
       "3                    1.332004     7.8  \n",
       "4                    1.130982     6.8  \n",
       "5                    1.122155     6.7  \n",
       "...                       ...     ...  \n",
       "60419                1.332004     7.8  \n",
       "60420                1.130982     6.8  \n",
       "60421                1.122155     6.7  \n",
       "60422                1.323012     6.7  \n",
       "60423                1.365916     6.4  \n",
       "\n",
       "[52922 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a blank row at the end of our dataframe to accomodate shifted data\n",
    "universe_df_with_external_factors_elongated = pd.concat([universe_df_with_external_factors, pd.DataFrame([[np.nan] * universe_df_with_external_factors.shape[1]], columns=universe_df_with_external_factors.columns)], ignore_index=True)\n",
    "\n",
    "#Move into factor model\n",
    "#Shift in -1 direction, rename to shifted return or similar\n",
    "#Shift our returns data forward by one period. This way, we regress \"t\" factors to \"t+1\" returns, and our betas become forecasts\n",
    "universe_df_with_external_factors_elongated['RET'] = universe_df_with_external_factors_elongated['RET'].shift(-1)\n",
    "\n",
    "#We want to remove our minimum date so that we have an equal number of periods across securities. Here we find the minimum date and remove rows with that date from our dataframe\n",
    "dtrmval = np.min(universe_df_with_external_factors_elongated.date)\n",
    "dtrmvalrangemax = dtrmval + timedelta(days=1)\n",
    "\n",
    "#Filter out our beginning date\n",
    "universe_df_with_external_factors_filtered = universe_df_with_external_factors_elongated[(universe_df_with_external_factors_elongated[\"date\"] >= dtrmvalrangemax)]\n",
    "#colnames = universe_df_with_external_factors_filtered.columns[4:6]\n",
    "#print(colnames)\n",
    "\n",
    "#display(universe_df_with_external_factors_filtered.iloc[:,3:])\n",
    "\n",
    "#Here, we select our required columns in proper order (see function documentation for more info) and get rid of extra columns that we will not use\n",
    "universe_df_with_external_factors_filtered = universe_df_with_external_factors_filtered[[\"PERMNO\",\"date\",\"RET\", \"Annualized Percent Change of GDP from Preceding Period, Seasonally Adjusted\",\"CPI (USACPALTT01CTGYM)\",\"UNRATE\"]]\n",
    "display(universe_df_with_external_factors_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63dc858a-2c12-496d-ae6e-cf3addb0f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We generate our list of unique tickers, this can be done in multiple different ways (in this case, using a previous df with distinct tickers)\n",
    "#listofPERMNO = observation_df[pd.to_numeric(observation_df['COUNT(PERMNO)']) >=37]\n",
    "#uniqueTickerList = listofPERMNO['PERMNO']\n",
    "#print(uniqueTickerList)\n",
    "#uniquetickerlist1 = universe_df_with_external_factors_filtered.iloc[:,0].unique()\n",
    "\n",
    "#universe_df_with_external_factors_filtered.columns\n",
    "#universe_df_with_external_factors_filtered.iloc[:,0]\n",
    "#print(universe_df_with_external_factors_filtered.iloc[:,0].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4f896cc-c30f-425c-91cd-8884058031b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the factor model that takes a dataframe of the required columns (unique identifier, date/index column, returns columns, and a set of factors)\n",
    "def olsfactormodel(df_attached, lookbackwindow:int):\n",
    "\n",
    "    #Assign passed dataframe to new dataframe\n",
    "    df = df_attached.copy(deep=True)\n",
    "    \n",
    "    #We generate our list of unique tickers using the column in the unique identifier position (0, or leftmost column)\n",
    "    uniqueTickerList = df.iloc[:,0].unique()\n",
    "    \n",
    "    #Initialize large df to drop results of regression for each security at each regression date\n",
    "    containerdf = pd.DataFrame()\n",
    "                \n",
    "    #Set our lookback window to 24 periods (months in this case). This means that we will run a regression for each period (after the first 24 months) using the previous 24 months as data\n",
    "    LookBack_Window=lookbackwindow\n",
    "    \n",
    "    #We will now create a new set of columns for the Beta and P-value for each of our factors. We will do this by iterating through each factor and columns for the beta coefficients\n",
    "    factorlist = list(df.columns[3:])\n",
    "    print(len(factorlist))\n",
    "    \n",
    "    #For each factor, define an empty column to hold the corresponding coefficient\n",
    "    for factor in factorlist: \n",
    "        df[\"Beta_\" + factor] = 0\n",
    "    \n",
    "    #Initialize global parameter(s) regardless of factor count\n",
    "    df[\"R_squared\"] = 0\n",
    "    df[\"Constant B0\"] = 0\n",
    "\n",
    "    #For each identifier (ticker), generate a dataframe from the broader dataframe that \n",
    "    for ticker in uniqueTickerList:\n",
    "        \n",
    "        #For each unique identifier (ticker), we create a dataframe with observations from that particular identifier\n",
    "        ticker_specific_universe_df = df.loc[df.iloc[:,0] == ticker]\n",
    "        \n",
    "        #We then sort our date/index column in position 1 to ensure our date is ascending from the earliest available\n",
    "        ticker_specific_universe_df = ticker_specific_universe_df.sort_values(by= ticker_specific_universe_df.columns[1])\n",
    "\n",
    "        #For each lookback window span, train an OLS and collect the results\n",
    "        for x in range(0, len(ticker_specific_universe_df)-LookBack_Window-1):\n",
    "            \n",
    "            # Define the independent variables (X) and dependent variable (Y). X's are defined by our factor columns and our returns are defined in our third left-most column (position 2)\n",
    "            X = ticker_specific_universe_df[factorlist][x:x+LookBack_Window]\n",
    "            Y = ticker_specific_universe_df[ticker_specific_universe_df.columns[2]][x:x+LookBack_Window]\n",
    "    \n",
    "            #Add a constant term to the independent variables, check impact\n",
    "            X = sm.add_constant(X)\n",
    "        \n",
    "            #Fit the linear regression model\n",
    "            model = sm.OLS(Y, X)\n",
    "            results = model.fit()\n",
    "            results.params\n",
    "            \n",
    "            #Place our regression coefficients into their appropriate columns\n",
    "            ticker_specific_universe_df.loc[ticker_specific_universe_df.index[x+1+LookBack_Window], \"Constant B0\"] = results.params[0]\n",
    "            ticker_specific_universe_df.loc[ticker_specific_universe_df.index[x+1+LookBack_Window], \"R_squared\"] = results.rsquared\n",
    "    \n",
    "            #We do the same dynamically using our list of factors and placing into the appropriate factor column\n",
    "    \n",
    "            #Define an index (starting position for inserting regression params)\n",
    "            i = 3 + len(factorlist) - 1\n",
    "            \n",
    "            for index in range(len(factorlist)):\n",
    "                #increase our indices by one for each factor\n",
    "                index+=1\n",
    "                i+=1\n",
    "                \n",
    "                ticker_specific_universe_df.loc[ticker_specific_universe_df.index[x+1+LookBack_Window], ticker_specific_universe_df.columns[i]] = results.params[index]\n",
    "        \n",
    "         \n",
    "        #Add ticker dataframe to larger container dataframe\n",
    "        containerdf = pd.concat([containerdf, ticker_specific_universe_df], ignore_index=True)   \n",
    "    return containerdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c51fdc-7191-4054-9524-166bc595f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m returnsdf \u001b[38;5;241m=\u001b[39m \u001b[43molsfactormodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muniverse_df_with_external_factors_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 66\u001b[0m, in \u001b[0;36molsfactormodel\u001b[1;34m(df_attached, lookbackwindow)\u001b[0m\n\u001b[0;32m     63\u001b[0m         index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     64\u001b[0m         i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 66\u001b[0m         ticker_specific_universe_df\u001b[38;5;241m.\u001b[39mloc[ticker_specific_universe_df\u001b[38;5;241m.\u001b[39mindex[x\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mLookBack_Window], ticker_specific_universe_df\u001b[38;5;241m.\u001b[39mcolumns[i]] \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#Add ticker dataframe to larger container dataframe\u001b[39;00m\n\u001b[0;32m     70\u001b[0m containerdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([containerdf, ticker_specific_universe_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)   \n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\series.py:1118\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[0;32m   1109\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1110\u001b[0m         \u001b[38;5;66;03m# GH#50617\u001b[39;00m\n\u001b[0;32m   1111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.__getitem__ treating keys as positions is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1116\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1117\u001b[0m     )\n\u001b[1;32m-> 1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "returnsdf = olsfactormodel(universe_df_with_external_factors_filtered,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d69dbb69-224f-441a-a30b-af5a2404de5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'returnsdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.min_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m display(\u001b[43mreturnsdf\u001b[49m[(returnsdf \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall(\u001b[38;5;241m1\u001b[39m)])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'returnsdf' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.min_rows', 500)\n",
    "display(returnsdf[(returnsdf != 0).all(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746c20b-207c-4d56-b21e-ac29538cbff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(0,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
